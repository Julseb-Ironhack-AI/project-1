{"cells":[{"cell_type":"markdown","id":"8b636fac","metadata":{"id":"8b636fac"},"source":["<a href=\"https://colab.research.google.com/drive/1pY6TXtBEpJbyLC5llcvWKmXOgTInFeD5\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","id":"1683803c","metadata":{"id":"1683803c"},"source":["# VGG 16 model"]},{"cell_type":"code","execution_count":null,"id":"083f5924","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"083f5924","outputId":"ff697b25-ebb5-45f8-db95-2f2330ad3167"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m 79462400/170498071\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 0us/step"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.utils import to_categorical\n","\n","# Load CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"]},{"cell_type":"code","execution_count":null,"id":"8e269886","metadata":{"id":"8e269886"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Classe names come from cifar10 dataset\n","class_names = [\n","    'airplane', 'automobile', 'bird', 'cat', 'deer',\n","    'dog', 'frog', 'horse', 'ship', 'truck'\n","]\n","\n","# Show 10 random images for each class\n","plt.figure(figsize=(10, 10))\n","images = []\n","for class_idx in range(10):\n","    idxs = np.where(y_train.flatten() == class_idx)[0]\n","    selected = np.random.choice(idxs, 10, replace=False)\n","    for i, img_idx in enumerate(selected):\n","        plt.subplot(10, 10, class_idx * 10 + i + 1)\n","        plt.imshow(x_train[img_idx])\n","        images.append(x_train[img_idx])\n","        plt.axis('off')\n","        if i == 0:\n","            plt.title(class_names[class_idx])\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"7425ad3a","metadata":{"id":"7425ad3a"},"outputs":[],"source":["# Convert classes to one-hot encoding\n","\n","y_train_onehot = to_categorical(y_train, num_classes=10)\n","y_test_onehot = to_categorical(y_test, num_classes=10)\n","\n","print(y_train_onehot.shape)\n","print(y_test_onehot.shape)"]},{"cell_type":"code","execution_count":null,"id":"42c944df","metadata":{"id":"42c944df"},"outputs":[],"source":["# Normalize the images\n","\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","print(x_train.shape)\n","print(x_test.shape)"]},{"cell_type":"code","execution_count":null,"id":"aaba7f7b","metadata":{"id":"aaba7f7b"},"outputs":[],"source":["# Create a simple Sequential model\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Flatten(),\n","    Dense(100, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"4e73309d","metadata":{"id":"4e73309d"},"outputs":[],"source":["# Compile the model\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer='sgd',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"id":"f9100238","metadata":{"id":"f9100238"},"outputs":[],"source":["# Create a model architecture\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","model = Sequential([\n","    # First convolutional block\n","    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n","    Conv2D(32, (3, 3), activation='relu', padding='same'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.25),\n","\n","    # Second convolutional block\n","    Conv2D(64, (3, 3), activation='relu', padding='same'),\n","    Conv2D(64, (3, 3), activation='relu', padding='same'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.25),\n","\n","    # Third convolutional block\n","    Conv2D(128, (3, 3), activation='relu', padding='same'),\n","    Conv2D(128, (3, 3), activation='relu', padding='same'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.25),\n","\n","    # Fully connected layers\n","    Flatten(),\n","    Dense(256, activation='relu'),\n","    Dropout(0.5),\n","    Dense(10, activation='softmax')\n","])\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"220df14a","metadata":{"id":"220df14a"},"outputs":[],"source":["# Compile the model using Adam optimizer\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer=Adam(learning_rate=0.001),\n","    metrics=['accuracy']\n",")\n","\n","# Early stopping callback: stop training if val_loss doesn't improve for 3 epochs\n","early_stop = EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    restore_best_weights=True\n",")\n","\n","# Train the model with early stopping\n","history = model.fit(\n","    x_train, y_train_onehot,\n","    epochs=30,\n","    batch_size=128,\n","    validation_data=(x_test, y_test_onehot),\n","    callbacks=[early_stop]\n",")"]},{"cell_type":"code","execution_count":null,"id":"909f5798","metadata":{"id":"909f5798"},"outputs":[],"source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate(x_test, y_test_onehot, verbose=0)\n","print(f\"Test Loss: {loss:.4f}\")\n","print(f\"Test Accuracy: {accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"l-sSSOMkac1p","metadata":{"id":"l-sSSOMkac1p"},"outputs":[],"source":["# Since accuracy is low, we want to make it higher\n","\n","# Reassign the patience for early_stop so we have more data to train\n","early_stop = EarlyStopping(\n","    monitor='val_loss',\n","    patience=10,\n","    restore_best_weights=True\n",")\n","\n","history = model.fit(\n","    x_train, y_train_onehot,\n","    epochs=200,  # Increased number of epochs\n","    batch_size=128,\n","    validation_data=(x_test, y_test_onehot),\n","    callbacks=[early_stop]\n",")\n","\n","# Evaluate the model on the test set again after extended training\n","loss, accuracy = model.evaluate(x_test, y_test_onehot, verbose=0)\n","print(f\"Test Loss: {loss:.4f}\")\n","print(f\"Test Accuracy: {accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"LNUkgSboar6K","metadata":{"id":"LNUkgSboar6K"},"outputs":[],"source":["# Let's increase the complexity of the model and use data augmentation\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Create data augmentation generator\n","datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True,\n","    zoom_range=0.1\n",")\n","\n","datagen.fit(x_train)\n","\n","# Create a more complex model architecture\n","model = Sequential([\n","    # First convolutional block\n","    Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n","    Conv2D(64, (3, 3), activation='relu', padding='same'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.3),\n","\n","    # Second convolutional block\n","    Conv2D(128, (3, 3), activation='relu', padding='same'),\n","    Conv2D(128, (3, 3), activation='relu', padding='same'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.4),\n","\n","    # Third convolutional block\n","    Conv2D(256, (3, 3), activation='relu', padding='same'),\n","    Conv2D(256, (3, 3), activation='relu', padding='same'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Dropout(0.4),\n","\n","    # Fully connected layers\n","    Flatten(),\n","    Dense(512, activation='relu'),\n","    Dropout(0.5),\n","    Dense(10, activation='softmax')\n","])\n","\n","model.summary()\n","\n"]},{"cell_type":"code","execution_count":null,"id":"LNCd0bHjWY2p","metadata":{"id":"LNCd0bHjWY2p"},"outputs":[],"source":["# Compile the model using Adam optimizer with a slightly lower learning rate\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer=Adam(learning_rate=0.0005),\n","    metrics=['accuracy']\n",")\n","\n","# Early stopping callback: stop training if val_loss doesn't improve for 10 epochs\n","early_stop = EarlyStopping(\n","    monitor='val_loss',\n","    patience=10,\n","    restore_best_weights=True\n",")\n","\n","# Train the model with data augmentation and early stopping\n","history = model.fit(\n","    datagen.flow(x_train, y_train_onehot, batch_size=128),\n","    epochs=200,  # Increased number of epochs\n","    validation_data=(x_test, y_test_onehot),\n","    callbacks=[early_stop]\n",")\n","\n","# Evaluate the model on the test set after training\n","loss, accuracy = model.evaluate(x_test, y_test_onehot, verbose=0)\n","print(f\"Test Loss: {loss:.4f}\")\n","print(f\"Test Accuracy: {accuracy:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"JUwiIS2dW04J","metadata":{"id":"JUwiIS2dW04J"},"outputs":[],"source":["# Plot training history\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Model Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Model Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"KZAVcH-abxFK","metadata":{"id":"KZAVcH-abxFK"},"outputs":[],"source":["# Evaluate the trained model on a separate validation set.\n","\n","# Load CIFAR-10 dataset to create a validation set\n","# Assuming x_train, y_train, x_test, y_test are already loaded from previous code\n","# Split the original test set into a validation set and a new test set\n","from sklearn.model_selection import train_test_split\n","\n","# Assuming x_test and y_test are the original test sets\n","x_val, x_test_new, y_val, y_test_new = train_test_split(x_test, y_test_onehot, test_size=0.5, random_state=42)\n","\n","print(f\"Original test set shape: {x_test.shape}\")\n","print(f\"New test set shape: {x_test_new.shape}\")\n","print(f\"Validation set shape: {x_val.shape}\")\n","\n","# Now evaluate the trained model on the validation set\n","loss_val, accuracy_val = model.evaluate(x_val, y_val, verbose=0)\n","print(f\"Validation Loss: {loss_val:.4f}\")\n","print(f\"Validation Accuracy: {accuracy_val:.4f}\")\n","\n","# You can also evaluate on the new test set to see performance on unseen data\n","loss_test_new, accuracy_test_new = model.evaluate(x_test_new, y_test_new, verbose=0)\n","print(f\"New Test Loss: {loss_test_new:.4f}\")\n","print(f\"New Test Accuracy: {accuracy_test_new:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"hqGEC60IiaVx","metadata":{"id":"hqGEC60IiaVx"},"outputs":[],"source":["# Compute and report metrics\n","\n","from sklearn.metrics import classification_report\n","\n","# Get predictions for the test set\n","y_pred = model.predict(x_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(y_test_onehot, axis=1)\n","\n","# Compute and print classification report\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))\n"]},{"cell_type":"code","execution_count":null,"id":"YX12YLcQijFO","metadata":{"id":"YX12YLcQijFO"},"outputs":[],"source":["# Visualize the confusion matrix to understand model performance across different classes.\n","\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","# Compute the confusion matrix\n","conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n","\n","# Visualize the confusion matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","plt.xlabel('Predicted Class')\n","plt.ylabel('True Class')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"08vJDGyxiqLL","metadata":{"id":"08vJDGyxiqLL"},"outputs":[],"source":["# Evaluate the accuracy of the model with VGG16\n","\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Load the VGG16 model with pre-trained weights on ImageNet\n","# We exclude the top (fully connected) layers so we can add our own\n","vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n","\n","# Freeze the convolutional layers of VGG16 to prevent their weights from being updated during training\n","for layer in vgg16_base.layers:\n","    layer.trainable = False\n","\n","# Create a new model on top of the VGG16 base and define the input layer\n","input_tensor = Input(shape=(32, 32, 3))\n","\n","# Pass the input through the VGG16 base model\n","x = vgg16_base(input_tensor)\n","\n","# Add our own classification layers\n","x = Flatten()(x)  # Flatten the output from the convolutional base\n","x = Dense(256, activation='relu')(x) # Add a dense layer with ReLU activation\n","x = Dropout(0.5)(x) # Add dropout for regularisation\n","output_tensor = Dense(10, activation='softmax')(x) # Add the output layer with softmax activation for 10 classes\n","\n","# Create the final model\n","vgg16_model = Model(inputs=input_tensor, outputs=output_tensor)\n","\n","# Compile the model\n","vgg16_model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer=Adam(learning_rate=0.001), # Use Adam optimizer\n","    metrics=['accuracy']\n",")\n","\n","vgg16_model.summary()\n","\n","# Early stopping callback\n","early_stop_vgg16 = EarlyStopping(\n","    monitor='val_loss',\n","    patience=10,\n","    restore_best_weights=True\n",")\n","\n","# Train the VGG16 model\n","# We'll use the same data augmentation setup as before\n","history_vgg16 = vgg16_model.fit(\n","    datagen.flow(x_train, y_train_onehot, batch_size=128),\n","    epochs=100, # Train for a reasonable number of epochs\n","    validation_data=(x_test, y_test_onehot),\n","    callbacks=[early_stop_vgg16]\n",")"]},{"cell_type":"code","execution_count":null,"id":"pW2EiXVki2Lm","metadata":{"id":"pW2EiXVki2Lm"},"outputs":[],"source":["# Evaluate the VGG16 model on the test set\n","loss_vgg16, accuracy_vgg16 = vgg16_model.evaluate(x_test, y_test_onehot, verbose=0)\n","print(f\"\\nVGG16 Model Test Loss: {loss_vgg16:.4f}\")\n","print(f\"VGG16 Model Test Accuracy: {accuracy_vgg16:.4f}\")\n","\n","# Get predictions for the test set using the VGG16 model\n","y_pred_vgg16 = vgg16_model.predict(x_test)\n","y_pred_classes_vgg16 = np.argmax(y_pred_vgg16, axis=1)\n","\n","# Compute and print classification report for VGG16\n","print(\"\\nVGG16 Model Classification Report:\")\n","print(classification_report(y_true_classes, y_pred_classes_vgg16, target_names=class_names))"]},{"cell_type":"code","execution_count":null,"id":"MvjFcvuDUFjs","metadata":{"id":"MvjFcvuDUFjs"},"outputs":[],"source":["# Compute and visualize the confusion matrix for VGG16\n","conf_matrix_vgg16 = confusion_matrix(y_true_classes, y_pred_classes_vgg16)\n","\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(conf_matrix_vgg16, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","plt.xlabel('Predicted Class')\n","plt.ylabel('True Class')\n","plt.title('VGG16 Model Confusion Matrix')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"f0ddbf18","metadata":{"id":"f0ddbf18"},"outputs":[],"source":["vgg16_model.save(\"vgg16_julien.kiras\")"]},{"cell_type":"markdown","id":"f1f297b4","metadata":{"id":"f1f297b4"},"source":["### Comments on the matrix\n","\n","- Strong Performance: The high values along the diagonal indicate that the VGG16 model correctly classifies most images for several classes.\n","- Common Confusions: Off-diagonal values show which classes are often confused. For example, 'cat' and 'dog' are frequently misclassified as each other, which is expected due to their visual similarity.\n","- Challenging Classes: Some classes, such as 'frog', 'deer', and 'bird', may have more misclassifications, possibly due to less distinctive features or similarities with other animals.\n","- Well-Separated Classes: Classes like 'airplane', 'ship', and 'automobile' tend to have fewer confusions, likely because their features are more distinct.\n","- Improvement Areas: The model could benefit from further fine-tuning, more data augmentation, or class-specific strategies to reduce confusion between visually similar categories.\n","\n","The VGG16 model achieves good classification accuracy on CIFAR-10, but there is still room for improvement, especially for classes that are visually similar. The confusion matrix is a valuable tool for identifying these weaknesses and guiding further model enhancements."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":5}